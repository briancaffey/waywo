{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Waywo - Getting Started\n",
    "\n",
    "This notebook demonstrates how to interact with the Waywo project's core components:\n",
    "\n",
    "1. **Database Access** - Query posts, comments, and projects using SQLAlchemy\n",
    "2. **Embedding Client** - Generate embeddings for text\n",
    "3. **Semantic Search** - Find similar projects\n",
    "4. **LLM Client** - Make LLM calls using the configured endpoint\n",
    "5. **Workflow Testing** - Run workflow components interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up the path and import our modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/app')\n",
    "\n",
    "# Enable async support in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db-header",
   "metadata": {},
   "source": [
    "## 1. Database Access\n",
    "\n",
    "The project uses SQLite with SQLAlchemy. Let's explore the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.db.database import SessionLocal\n",
    "from src.db.models import WaywoPostDB, WaywoCommentDB, WaywoProjectDB\n",
    "from src.db import client as db_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Statistics:\n",
      "  Posts: 39\n",
      "  Comments: 8708\n",
      "  Projects: 444\n",
      "  Processed comments: 385\n",
      "  Valid projects: 443\n",
      "  Projects with embeddings: 443\n"
     ]
    }
   ],
   "source": [
    "# Get database statistics\n",
    "stats = db_client.get_database_stats()\n",
    "print(\"Database Statistics:\")\n",
    "print(f\"  Posts: {stats['posts_count']}\")\n",
    "print(f\"  Comments: {stats['comments_count']}\")\n",
    "print(f\"  Projects: {stats['projects_count']}\")\n",
    "print(f\"  Processed comments: {stats['processed_comments_count']}\")\n",
    "print(f\"  Valid projects: {stats['valid_projects_count']}\")\n",
    "print(f\"  Projects with embeddings: {stats['projects_with_embeddings_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db-query-posts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 posts:\n",
      "\n",
      "  [30516198] Ask HN: What are you working on? (March 2022) - 1 comments\n",
      "  [30883352] Ask HN: What Are You Up To? (April 2022) - 24 comments\n",
      "  [31236618] Ask HN: What Are You Working On? (May 2022) - 10 comments\n",
      "  [31949485] Ask HN: What Are You Working On? (July 2022) - 2 comments\n",
      "  [32309210] Ask HN: What Are You Working On? (August 2022) - 41 comments\n"
     ]
    }
   ],
   "source": [
    "# Query recent posts\n",
    "post_ids = db_client.get_all_post_ids()[:5]  # Get first 5\n",
    "print(f\"Found {len(post_ids)} posts:\\n\")\n",
    "for post_id in post_ids:\n",
    "    post = db_client.get_post(post_id)\n",
    "    if post:\n",
    "        comment_count = db_client.get_comment_count_for_post(post.id)\n",
    "        print(f\"  [{post.id}] {post.title} - {comment_count} comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db-query-comments",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 comments:\n",
      "\n",
      "  [46378010] by Colin_S: I&#x27;m working on Lumi AI (<a href=\"https:&#x2F;&#x2F;apps.shopify.com&#x2F;lumi-ai-seo-alt-text\" ...\n",
      "\n",
      "  [46374571] by flavioaiello: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;magikrun\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2...\n",
      "\n",
      "  [46370640] by stevenicr: working on a hybrid done with you quick website launches ( <a href=\"https:&#x2F;&#x2F;betterwebgroup...\n",
      "\n",
      "  [46333890] by bitstrategist: heyy i am rachel Joseph , i am bit strategist \n",
      "A seasoned blockchain strategist with a decade of exp...\n",
      "\n",
      "  [46326590] by tungnt620: <a href=\"https:&#x2F;&#x2F;pocketbasecloud.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;pocketbaseclo...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query comments (with optional post_id filter)\n",
    "comments = db_client.get_all_comments(limit=5)\n",
    "print(f\"Found {len(comments)} comments:\\n\")\n",
    "for comment in comments:\n",
    "    text_preview = comment.text[:100] + \"...\" if len(comment.text) > 100 else comment.text\n",
    "    print(f\"  [{comment.id}] by {comment.by}: {text_preview}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db-query-projects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 projects:\n",
      "\n",
      "  [451] Polingo Interactive Language Learning\n",
      "      Scores: idea=8, complexity=7\n",
      "      Tags: language, learning, ai, education, app\n",
      "\n",
      "  [450] Tinqer: TypeScript LINQ-to-SQL Port\n",
      "      Scores: idea=6, complexity=7\n",
      "      Tags: typescript, linq, database, open-source, query\n",
      "\n",
      "  [449] Decentralized Global Social Feed\n",
      "      Scores: idea=8, complexity=9\n",
      "      Tags: web3, decentralized, social, blockchain, p2p\n",
      "\n",
      "  [448] Credit Card Rewards Optimizer\n",
      "      Scores: idea=8, complexity=6\n",
      "      Tags: fintech, rewards, optimization, personal finance\n",
      "\n",
      "  [447] DB Pro Desktop Database Workbench\n",
      "      Scores: idea=8, complexity=7\n",
      "      Tags: database, electron, react, ai, productivity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query projects\n",
    "projects = db_client.get_all_projects(limit=5)\n",
    "print(f\"Found {len(projects)} projects:\\n\")\n",
    "for project in projects:\n",
    "    print(f\"  [{project.id}] {project.title}\")\n",
    "    print(f\"      Scores: idea={project.idea_score}, complexity={project.complexity_score}\")\n",
    "    print(f\"      Tags: {', '.join(project.hashtags) if project.hashtags else 'None'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-header",
   "metadata": {},
   "source": [
    "## 2. Embedding Client\n",
    "\n",
    "The embedding client connects to an external embedding service to generate vector embeddings for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "embedding-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding service URL: http://192.168.5.96:8000\n",
      "Embedding service healthy: True\n"
     ]
    }
   ],
   "source": [
    "from src.clients.embedding import (\n",
    "    get_single_embedding, \n",
    "    get_embeddings, \n",
    "    check_embedding_service_health,\n",
    "    DEFAULT_EMBEDDING_URL\n",
    ")\n",
    "import asyncio\n",
    "\n",
    "# Check health\n",
    "async def check_health():\n",
    "    return await check_embedding_service_health()\n",
    "\n",
    "is_healthy = asyncio.get_event_loop().run_until_complete(check_health())\n",
    "print(f\"Embedding service URL: {DEFAULT_EMBEDDING_URL}\")\n",
    "print(f\"Embedding service healthy: {is_healthy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "embedding-generate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embedding for: 'A machine learning tool for analyzing code repositories'\n",
      "Embedding dimension: 4096\n",
      "First 10 values: [0.00121307373046875, -0.0030517578125, 0.01434326171875, -0.001983642578125, -0.00084686279296875, -0.000885009765625, 0.0169677734375, -0.004364013671875, 0.0277099609375, -0.00848388671875]\n"
     ]
    }
   ],
   "source": [
    "# Generate an embedding for sample text\n",
    "sample_text = \"A machine learning tool for analyzing code repositories\"\n",
    "\n",
    "async def generate_embedding():\n",
    "    try:\n",
    "        return await get_single_embedding(sample_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "embedding = asyncio.get_event_loop().run_until_complete(generate_embedding())\n",
    "\n",
    "if embedding:\n",
    "    print(f\"Generated embedding for: '{sample_text}'\")\n",
    "    print(f\"Embedding dimension: {len(embedding)}\")\n",
    "    print(f\"First 10 values: {embedding[:10]}\")\n",
    "else:\n",
    "    print(\"Failed to generate embedding (service may be unavailable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-header",
   "metadata": {},
   "source": [
    "## 3. Semantic Search\n",
    "\n",
    "Use vector embeddings to find semantically similar projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "search-stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total projects: 444\n",
      "Projects with embeddings: 443\n",
      "Coverage: 99.8%\n"
     ]
    }
   ],
   "source": [
    "# Check embedding coverage\n",
    "total_projects = db_client.get_total_project_count()\n",
    "projects_with_embeddings = db_client.get_projects_with_embeddings_count()\n",
    "\n",
    "print(f\"Total projects: {total_projects}\")\n",
    "print(f\"Projects with embeddings: {projects_with_embeddings}\")\n",
    "if total_projects > 0:\n",
    "    print(f\"Coverage: {projects_with_embeddings / total_projects * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "search-query",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic search results for: 'AI tools for developers'\n",
      "\n",
      "  [0.844] AI Hacker Builder\n",
      "           Autonomous AI that generates secure code\n",
      "\n",
      "  [0.815] Non-LLM AI Modeling Paradigm\n",
      "           AI approach focusing on modeling rather than scaling text prediction\n",
      "\n",
      "  [0.812] AI Study Buddy\n",
      "           Peer-level AI study companion for high school students\n",
      "\n",
      "  [0.811] Personal AI Photography Hub\n",
      "           AI-driven site for automatic photo tagging and color discovery\n",
      "\n",
      "  [0.810] AI Human Interaction Research Robot\n",
      "           A robot studying AI-human interaction dynamics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform semantic search\n",
    "query = \"AI tools for developers\"\n",
    "\n",
    "async def get_query_embedding():\n",
    "    try:\n",
    "        return await get_single_embedding(query)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "query_embedding = asyncio.get_event_loop().run_until_complete(get_query_embedding())\n",
    "\n",
    "if query_embedding:\n",
    "    results = db_client.semantic_search(query_embedding, limit=5)\n",
    "    print(f\"Semantic search results for: '{query}'\\n\")\n",
    "    for project, similarity in results:\n",
    "        print(f\"  [{similarity:.3f}] {project.title}\")\n",
    "        print(f\"           {project.short_description}\\n\")\n",
    "else:\n",
    "    print(\"Could not generate query embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6jm4dv1oet",
   "metadata": {},
   "source": [
    "## 3.5 Rerank Service\n",
    "\n",
    "The rerank service uses a cross-encoder model to improve retrieval quality by reranking candidates based on query-document relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "s6gw1obpir",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0xffffb1dc1940> is already entered\n",
      "Rerank service health check failed: All connection attempts failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerank service URL: http://192.168.5.173:8111\n",
      "Rerank service healthy: False\n"
     ]
    }
   ],
   "source": [
    "from src.clients.rerank import (\n",
    "    rerank_documents,\n",
    "    check_rerank_service_health,\n",
    "    DEFAULT_RERANK_URL\n",
    ")\n",
    "\n",
    "# Check rerank service health\n",
    "async def check_rerank_health():\n",
    "    return await check_rerank_service_health()\n",
    "\n",
    "is_healthy = asyncio.get_event_loop().run_until_complete(check_rerank_health())\n",
    "print(f\"Rerank service URL: {DEFAULT_RERANK_URL}\")\n",
    "print(f\"Rerank service healthy: {is_healthy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1yf7937d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reranking with sample documents\n",
    "query = \"AI tools for developers\"\n",
    "documents = [\n",
    "    \"A machine learning framework for building neural networks\",\n",
    "    \"A recipe app for cooking enthusiasts\",\n",
    "    \"An AI-powered code review tool that suggests improvements\",\n",
    "    \"A weather forecasting service for farmers\",\n",
    "    \"A developer productivity tool using LLMs for code generation\"\n",
    "]\n",
    "\n",
    "async def test_rerank():\n",
    "    try:\n",
    "        result = await rerank_documents(query, documents)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "result = asyncio.get_event_loop().run_until_complete(test_rerank())\n",
    "\n",
    "if result:\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(\"Reranked documents (by relevance):\")\n",
    "    for i, idx in enumerate(result.ranked_indices):\n",
    "        score = result.scores[idx]\n",
    "        doc = documents[idx][:60] + \"...\" if len(documents[idx]) > 60 else documents[idx]\n",
    "        print(f\"  {i+1}. [{score:+.2f}] {doc}\")\n",
    "else:\n",
    "    print(\"Reranking failed (service may be unavailable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": [
    "## 4. LLM Client\n",
    "\n",
    "The project uses an OpenAI-compatible LLM endpoint (Nemotron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "llm-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM configured:\n",
      "  Model: nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\n",
      "  Base URL: http://192.168.6.19:8002/v1\n"
     ]
    }
   ],
   "source": [
    "from src.llm_config import get_llm\n",
    "\n",
    "llm = get_llm()\n",
    "print(f\"LLM configured:\")\n",
    "print(f\"  Model: {llm.model}\")\n",
    "print(f\"  Base URL: {llm.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-complete",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Make a simple LLM call\n",
    "async def test_llm():\n",
    "    prompt = \"What are three key features of a good developer tool? Be brief.\"\n",
    "    response = await llm.acomplete(prompt)\n",
    "    return response.text\n",
    "\n",
    "result = asyncio.get_event_loop().run_until_complete(test_llm())\n",
    "print(\"LLM Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workflow-header",
   "metadata": {},
   "source": [
    "## 5. Workflow Testing\n",
    "\n",
    "Test the LlamaIndex workflow components interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "workflow-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.workflows.waywo_project_workflow import WaywoProjectWorkflow\n",
    "\n",
    "# Create workflow instance\n",
    "workflow = WaywoProjectWorkflow(timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "workflow-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample comment\n",
    "sample_comment = \"\"\"\n",
    "I've been building a CLI tool called 'codestat' that analyzes your git repositories \n",
    "and generates insights about your coding patterns. It tracks things like:\n",
    "- Most active times of day\n",
    "- Language usage over time\n",
    "- Commit frequency patterns\n",
    "\n",
    "Check it out: https://github.com/example/codestat\n",
    "\"\"\"\n",
    "\n",
    "async def run_workflow():\n",
    "    result = await workflow.run(comment_text=sample_comment, comment_id=99999)\n",
    "    return result\n",
    "\n",
    "# Note: This will make multiple LLM calls and may take a minute\n",
    "# Uncomment the following lines to run:\n",
    "# result = asyncio.get_event_loop().run_until_complete(run_workflow())\n",
    "# print(f\"Workflow completed. Projects extracted: {len(result) if result else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chatbot-header",
   "metadata": {},
   "source": [
    "## 6. RAG Chatbot (with Reranking)\n",
    "\n",
    "Test the RAG chatbot workflow that answers questions using project data. The chatbot now uses semantic search + reranking for improved retrieval quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "chatbot-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
     ]
    }
   ],
   "source": [
    "from src.workflows.waywo_chatbot_workflow import WaywoChatbotWorkflow\n",
    "\n",
    "chatbot = WaywoChatbotWorkflow(top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "chatbot-query",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What AI or machine learning projects are people working on?\n",
      "\n",
      "Response:\n",
      "\n",
      "Here are some of the AI‑ and ML‑focused projects that have been shared in the recent “What are you working on?” threads on Hacker News:\n",
      "\n",
      "| # | Project (as posted) | Relevance | Idea Score | Complexity | Brief description | Tags |\n",
      "|---|----------------------|-----------|------------|------------|-------------------|------|\n",
      "| 1 | **Non‑LLM AI Modeling Paradigm** | 81 % | 7/10 | 6/10 | A new way to think about AI that treats it as a **modeling problem** rather than simply scaling up text‑prediction models. It explores alternative architectures and training strategies that could be more efficient or specialized. | #ai, #modeling, #ml, #paradigm |\n",
      "| 2 | **AI Hacker Builder** | 79 % | 5/10 | 6/10 | An **autonomous AI system** that generates secure code, aiming to close the gap between the high demand for secure software and the limited supply of developers who can write it safely. | #ai, #security, #cybersecurity, #code, #productivity |\n",
      "| 3 | **Personal AI Photography Hub** | 78 % | 6/10 | 6/10 | A personal photography site that leverages AI for **automatic tagging, color extraction, and novel discovery**. It turns a private photo library into a searchable, AI‑enhanced collection. | #ai, #photography, #color, #discovery |\n",
      "| 4 | **CraftCX AI Support Observability** | 76 % | 7/10 | 6/10 | A platform that **monitors AI‑powered customer‑support agents**, tracking performance metrics and evaluating the quality of the resolutions they produce. Helps teams maintain trust and reliability in AI‑driven support. | #ai, #support, #observability, #trust, #saas |\n",
      "| 5 | **HN Jobs Assistant** | 76 % | 6/10 | 6/10 | A **chat‑assistant** that indexes Hacker News hiring threads and suggests roles that match a user’s skills and interests, acting as a lightweight open‑source recruiting aid. | #ai, #rag, #hiring, #jobs, #opensource |\n",
      "\n",
      "### What this tells us\n",
      "- **Modeling‑first AI** (Project 1) is attracting attention as a potential alternative to the “bigger‑is‑better” LLM mindset.\n",
      "- **Security‑oriented code generation** (Project 2) is seen as a practical way to boost productivity while keeping codebases safe.\n",
      "- **Personal creative tools** (Project 3) are popular for leveraging AI to enrich hobbyist workflows like photography.\n",
      "- **Observability for AI services** (Project 4) reflects growing concerns about reliability and trust when AI agents interact with real users.\n",
      "- **AI‑augmented recruiting** (Project 5) shows how developers are experimenting with open‑source bots to make sense of community‑generated job data.\n",
      "\n",
      "If you’re looking for inspiration or want to dive deeper into any of these ideas, let me know which one catches your eye and I can share more details (e.g., implementation approaches, open‑source repos, or related discussions).\n",
      "\n",
      "Source projects: 5\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"What AI or machine learning projects are people working on?\"\n",
    "\n",
    "async def run_chat():\n",
    "    result = await chatbot.chat(query)\n",
    "    return result\n",
    "\n",
    "response = asyncio.get_event_loop().run_until_complete(run_chat())\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Response:\\n{response.response}\")\n",
    "print(f\"\\nSource projects: {len(response.source_projects)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raw-sql-header",
   "metadata": {},
   "source": [
    "## 7. Raw SQL Queries\n",
    "\n",
    "For more complex analysis, you can run raw SQL queries directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raw-sql",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "from src.db.database import SessionLocal\n",
    "\n",
    "with SessionLocal() as session:\n",
    "    # Example: Get top hashtags by frequency\n",
    "    result = session.execute(text(\"\"\"\n",
    "        SELECT hashtags, COUNT(*) as count \n",
    "        FROM waywo_projects \n",
    "        WHERE hashtags IS NOT NULL AND hashtags != '[]'\n",
    "        GROUP BY hashtags \n",
    "        ORDER BY count DESC \n",
    "        LIMIT 10\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"Top hashtag combinations:\")\n",
    "    for row in result:\n",
    "        print(f\"  {row.hashtags}: {row.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "raw-sql-scores",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idea score distribution:\n",
      "  1: ## (2)\n",
      "  5: ### (3)\n",
      "  6: ####################### (23)\n",
      "  7: ############ (12)\n",
      "  8: ##### (5)\n"
     ]
    }
   ],
   "source": [
    "with SessionLocal() as session:\n",
    "    # Example: Distribution of idea scores\n",
    "    result = session.execute(text(\"\"\"\n",
    "        SELECT idea_score, COUNT(*) as count \n",
    "        FROM waywo_projects \n",
    "        WHERE idea_score IS NOT NULL\n",
    "        GROUP BY idea_score \n",
    "        ORDER BY idea_score\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"Idea score distribution:\")\n",
    "    for row in result:\n",
    "        bar = \"#\" * row.count\n",
    "        print(f\"  {row.idea_score}: {bar} ({row.count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "v9xsgb9gpe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments: 8705\n",
      "Dead comments: 153\n",
      "Dead percentage: 1.8%\n",
      "Live comments: 8552\n"
     ]
    }
   ],
   "source": [
    "# Count \"dead\" comments\n",
    "with SessionLocal() as session:\n",
    "    total_comments = session.execute(text(\"SELECT COUNT(*) FROM waywo_comments\")).scalar()\n",
    "    dead_comments = session.execute(text(\"SELECT COUNT(*) FROM waywo_comments WHERE text = '[dead]'\")).scalar()\n",
    "    \n",
    "    print(f\"Total comments: {total_comments}\")\n",
    "    print(f\"Dead comments: {dead_comments}\")\n",
    "    print(f\"Dead percentage: {dead_comments / total_comments * 100:.1f}%\")\n",
    "    print(f\"Live comments: {total_comments - dead_comments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Explore the `src/` directory for more modules\n",
    "- Check `src/db/client.py` for all available database operations\n",
    "- See `src/workflows/` for workflow implementations\n",
    "- See `src/clients/` for embedding, rerank, and other service clients\n",
    "- Use `src/main.py` as reference for API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330e6e9-625e-48dc-a9e9-0bf23872eff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

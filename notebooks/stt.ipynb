{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Speech-to-Text Client - Walkthrough\n",
    "\n",
    "This notebook demonstrates how to use the STT client (Nemotron Speech Streaming).\n",
    "\n",
    "1. **Health Check** - Verify STT service is reachable\n",
    "2. **Transcribe Audio** - Transcribe a WAV file\n",
    "3. **Word Timestamps** - Show word-level timing\n",
    "4. **Round-trip** - Generate speech with TTS, then transcribe it back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/app')\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "health-header",
   "metadata": {},
   "source": [
    "## 1. Health Check\n",
    "\n",
    "First, let's verify the STT service is running and reachable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "health-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STT URL: http://192.168.5.96:8001\n",
      "STT healthy: True\n"
     ]
    }
   ],
   "source": [
    "from src.clients.stt import (\n",
    "    check_stt_health,\n",
    "    transcribe_audio,\n",
    "    DEFAULT_STT_URL,\n",
    ")\n",
    "\n",
    "async def check_health():\n",
    "    return await check_stt_health()\n",
    "\n",
    "is_healthy = asyncio.get_event_loop().run_until_complete(check_health())\n",
    "print(f\"STT URL: {DEFAULT_STT_URL}\")\n",
    "print(f\"STT healthy: {is_healthy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transcribe-header",
   "metadata": {},
   "source": [
    "## 2. Transcribe a WAV File\n",
    "\n",
    "Load a WAV file and transcribe it with word-level timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transcribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 159788 bytes from /app/media/tts_samples/sample.wav\n",
      "\n",
      "Transcription: Welcome to Wei Wo, the platform that showcases what makers are working on.\n"
     ]
    }
   ],
   "source": [
    "# Load a WAV file (e.g., one generated by the TTS notebook)\n",
    "wav_path = Path(\"/app/media/tts_samples/sample.wav\")\n",
    "\n",
    "if wav_path.exists():\n",
    "    audio_bytes = wav_path.read_bytes()\n",
    "    print(f\"Loaded {len(audio_bytes)} bytes from {wav_path}\")\n",
    "\n",
    "    async def transcribe():\n",
    "        return await transcribe_audio(audio_bytes, timestamps=True)\n",
    "\n",
    "    result = asyncio.get_event_loop().run_until_complete(transcribe())\n",
    "    print(f\"\\nTranscription: {result.text}\")\n",
    "else:\n",
    "    print(f\"No WAV file found at {wav_path}\")\n",
    "    print(\"Run the TTS notebook first to generate a sample.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timestamps-header",
   "metadata": {},
   "source": [
    "## 3. Word-Level Timestamps\n",
    "\n",
    "Display the word-level timing information (used for subtitle generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "timestamps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word               Start      End Duration\n",
      "---------------------------------------------\n",
      "Welcome            0.16s    0.32s    0.16s\n",
      "to                 0.32s    0.40s    0.08s\n",
      "Wei                1.12s    1.20s    0.08s\n",
      "Wo,                1.28s    1.60s    0.32s\n",
      "the                1.60s    1.68s    0.08s\n",
      "platform           1.68s    1.84s    0.16s\n",
      "that               1.84s    1.92s    0.08s\n",
      "showcases          1.92s    2.40s    0.48s\n",
      "what               2.48s    2.56s    0.08s\n",
      "makers             2.64s    2.96s    0.32s\n",
      "are                2.96s    3.04s    0.08s\n",
      "working            3.04s    3.12s    0.08s\n",
      "on.                3.44s    3.60s    0.16s\n",
      "\n",
      "Total duration: 3.60s\n",
      "Total words: 13\n"
     ]
    }
   ],
   "source": [
    "if 'result' in dir() and result.words:\n",
    "    print(f\"{'Word':<15} {'Start':>8} {'End':>8} {'Duration':>8}\")\n",
    "    print(\"-\" * 45)\n",
    "    for w in result.words:\n",
    "        duration = w.end - w.start\n",
    "        print(f\"{w.word:<15} {w.start:>7.2f}s {w.end:>7.2f}s {duration:>7.2f}s\")\n",
    "    \n",
    "    total_duration = result.words[-1].end\n",
    "    print(f\"\\nTotal duration: {total_duration:.2f}s\")\n",
    "    print(f\"Total words: {len(result.words)}\")\n",
    "else:\n",
    "    print(\"No transcription result with timestamps available.\")\n",
    "    print(\"Run the cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roundtrip-header",
   "metadata": {},
   "source": [
    "## 4. TTS -> STT Round-trip\n",
    "\n",
    "Generate speech from text, then transcribe it back to verify the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "roundtrip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTS generated 108588 bytes\n",
      "\n",
      "Original:    The quick brown fox jumps over the lazy dog.\n",
      "Transcribed: The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "Word timestamps (9 words):\n",
      "  [0.24s - 0.32s] The\n",
      "  [0.48s - 0.56s] quick\n",
      "  [0.64s - 0.88s] brown\n",
      "  [1.12s - 1.20s] fox\n",
      "  [1.28s - 1.44s] jumps\n",
      "  [1.44s - 1.52s] over\n",
      "  [1.60s - 1.68s] the\n",
      "  [1.76s - 2.32s] lazy\n",
      "  [2.32s - 2.48s] dog.\n"
     ]
    }
   ],
   "source": [
    "from src.clients.tts import generate_speech\n",
    "\n",
    "original_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "async def roundtrip():\n",
    "    # Step 1: Text -> Speech\n",
    "    wav = await generate_speech(text=original_text)\n",
    "    print(f\"TTS generated {len(wav)} bytes\")\n",
    "\n",
    "    # Step 2: Speech -> Text\n",
    "    result = await transcribe_audio(wav, timestamps=True)\n",
    "    return result\n",
    "\n",
    "rt_result = asyncio.get_event_loop().run_until_complete(roundtrip())\n",
    "print(f\"\\nOriginal:    {original_text}\")\n",
    "print(f\"Transcribed: {rt_result.text}\")\n",
    "\n",
    "if rt_result.words:\n",
    "    print(f\"\\nWord timestamps ({len(rt_result.words)} words):\")\n",
    "    for w in rt_result.words:\n",
    "        print(f\"  [{w.start:.2f}s - {w.end:.2f}s] {w.word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See `src/clients/stt.py` for the full client API\n",
    "- Word timestamps are used by the subtitle overlay step in the video pipeline\n",
    "- The TTS -> STT pipeline provides both audio and timing data for MoviePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8ca78-50c9-439d-872c-ec4e19ea1557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

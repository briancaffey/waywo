---
title: WebSocket Protocol
description: The voice chat WebSocket message format — client commands, server events, and debug telemetry.
navigation.icon: i-lucide-plug-zap
---

# WebSocket Protocol

Voice Mode uses a single WebSocket connection at `/ws/voice-chat` for bidirectional communication. The protocol supports both text frames (JSON messages) and binary frames (audio data).

## Connection

Connect to the WebSocket with an optional `thread_id` query parameter:

```
ws://localhost:8008/ws/voice-chat
ws://localhost:8008/ws/voice-chat?thread_id=<uuid>
```

If `thread_id` is omitted, the backend creates a new thread and returns its ID in the initial `state` message. If provided, the backend loads the existing thread for conversation history.

## Client → Server Messages

### Text Frames (JSON)

| Message | Description |
|---------|-------------|
| `{"type": "start_listening"}` | Begin a voice turn — backend opens STT connection, expects audio |
| `{"type": "stop_listening"}` | End recording — backend finalizes STT, starts LLM + TTS |
| `{"type": "cancel"}` | Cancel the current turn and return to idle |
| `{"type": "set_voice", "voice": "..."}` | Change the TTS voice for this session (or `null` for default) |

### Binary Frames

Raw PCM audio data: **16-bit signed little-endian, 16kHz, mono**. Sent in ~4096-sample chunks (~256ms of audio) while in the `listening` state.

## Server → Client Messages

### Text Frames (JSON)

| Message | Description |
|---------|-------------|
| `{"type": "state", "state": "idle", "thread_id": "..."}` | State transition. The initial message includes `thread_id`. |
| `{"type": "stt_partial", "text": "..."}` | Partial transcription (real-time, updates as user speaks) |
| `{"type": "stt_final", "text": "..."}` | Final transcription of the user's speech |
| `{"type": "llm_complete", "text": "..."}` | Full LLM response text |
| `{"type": "turn_complete"}` | Turn finished — all audio sent, ready for next turn |
| `{"type": "error", "message": "..."}` | Error occurred during the turn |
| `{"type": "debug", ...}` | Debug telemetry event (see below) |

### Binary Frames

WAV audio data (LINEAR_PCM, 22050Hz) — the TTS-generated response audio. Sent as a single frame after the `llm_complete` text message.

## Debug Events

Debug events provide real-time visibility into backend processing. Each event has:

```json
{
  "type": "debug",
  "category": "stt",
  "event": "ws_connected",
  "data": { "url": "ws://...", "connect_ms": 12 },
  "ts": "2025-01-15T10:30:00.123Z"
}
```

### Categories

| Category | Color | Events |
|----------|-------|--------|
| **stt** | Blue | `ws_connected`, `chunks_forwarded`, `end_sent`, `partial`, `final`, `ws_closed`, `empty_result`, `error`, `timeout` |
| **llm** | Purple | `request_started`, `response_complete`, `empty_response` |
| **tts** | Green | `voice_changed`, `request_started`, `audio_received` |
| **audio** | Orange | `sent_to_client` |
| **ws** | Gray | `connected`, `turn_error`, `saving_turns`, `turns_saved` |
| **state** | Yellow | `transition` (includes timing: `stt_ms`, `llm_ms`, `tts_ms`, `turn_total_ms`) |

## Typical Turn Sequence

```
Client                          Server
  |                               |
  |-- start_listening ----------->|  (opens STT WebSocket)
  |-- [binary PCM chunks] ------>|  (forwards to STT)
  |<-- stt_partial --------------|  (real-time transcription)
  |<-- stt_partial --------------|
  |-- stop_listening ----------->|  (sends END to STT)
  |<-- state: processing --------|
  |<-- stt_final ----------------|  (final transcription)
  |<-- llm_complete -------------|  (full LLM response)
  |<-- state: speaking ----------|
  |<-- [binary WAV audio] -------|  (TTS audio)
  |<-- turn_complete ------------|
  |<-- state: idle --------------|
  |                               |
```

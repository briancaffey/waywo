---
title: Embedding Service
description: FastAPI microservice running llama-embed-nemotron-8b for generating 4096-dimensional vector embeddings.
navigation.icon: i-lucide-arrow-right-left
---

# Embedding Service

The embedding service runs the `nvidia/llama-embed-nemotron-8b` model as a standalone FastAPI microservice. It converts text into 4096-dimensional vectors used for semantic search across the project database.

## Model Details

| Property | Value |
|----------|-------|
| Model | `nvidia/llama-embed-nemotron-8b` |
| Parameters | 8B |
| Output Dimension | 4096 |
| Distance Metric | Cosine |
| Framework | FastAPI + Uvicorn |

## API Endpoints

### POST /embed

Generate embeddings for one or more documents.

**Request:**
```json
{
  "documents": ["First document text", "Second document text"]
}
```

**Response:**
```json
{
  "embeddings": [[0.1, 0.2, ...], [0.3, 0.4, ...]]
}
```

Each inner array contains exactly 4096 float values.

### GET /health

Returns service health status. Used by the WAYWO backend to verify the embedding service is available before processing.

## Client Configuration

The Python client in `src/embedding_client.py` connects to the service with built-in resilience:

| Setting | Value |
|---------|-------|
| Max Retries | 3 |
| Backoff Strategy | Exponential (`2^attempt` seconds) |
| Timeout | 60 seconds |
| Default URL | `http://192.168.5.96:8000` |

The client retries on timeout and connection errors with exponential backoff. HTTP status errors (4xx/5xx) are not retried -- they raise `EmbeddingError` immediately.

## Client Functions

| Function | Description |
|----------|-------------|
| `get_embeddings(texts)` | Embed a list of documents, returns list of vectors |
| `get_single_embedding(text)` | Convenience wrapper for a single document |
| `embedding_to_blob(embedding)` | Convert float list to binary blob for SQLite storage |
| `blob_to_embedding(blob)` | Convert binary blob back to float list |
| `create_embedding_text(title, description, hashtags)` | Build the combined text string used for embedding |
| `check_embedding_service_health(url)` | Returns `True` if the service is healthy |

## What Gets Embedded

Each project is embedded as a single combined text string:

```
{title}
{description}
#{tag1} #{tag2} #{tag3}
```

This concatenation is produced by `create_embedding_text()` and ensures that the embedding captures the project name, what it does, and its topic tags in a single vector.

## Storage

Embeddings are stored as binary blobs in the `description_embedding` column of the `waywo_projects` SQLite table. The `embedding_to_blob()` function packs the 4096 floats into little-endian 32-bit format compatible with the `sqlite-vector` extension.

## Running the Service

```bash
cd services/embedding-service
uv sync              # install dependencies
uv run uvicorn main:app --host 0.0.0.0 --port 8000
```

For flash attention support (faster inference on compatible GPUs):

```bash
uv sync --extra flash
```

## Source Files

- **Service**: `services/embedding-service/`
- **Client**: `src/embedding_client.py`
- **Model reference**: [nvidia/llama-embed-nemotron-8b on HuggingFace](https://huggingface.co/nvidia/llama-embed-nemotron-8b)

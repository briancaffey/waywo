---
title: Prompt Templates
description: All LLM prompt templates used in the WAYWO pipeline for project extraction, validation, metadata generation, scoring, and chatbot responses.
navigation.icon: i-lucide-file-text
---

# Prompt Templates

All LLM interactions in WAYWO use structured prompt templates defined in `src/workflows/prompts.py`. Every prompt instructs the model to return JSON, enforced through explicit formatting instructions rather than function calling.

## Prompt Summary

| Step | Prompt Purpose | Key Instructions | Output Format |
|------|---------------|-----------------|---------------|
| 1 | Extract Projects | Split multi-project HN comments into individual descriptions | JSON array of strings |
| 2 | Validate Project | Determine if text describes a real project | `{is_valid, reason}` |
| 3 | Generate Metadata | Produce title, description, tags, URL summaries | `{title, short_description, description, hashtags, url_summaries}` |
| 4 | Score Project | Rate idea quality and implementation complexity 1-10 | `{idea_score, complexity_score, idea_reasoning, complexity_reasoning}` |
| 5 | Chatbot Response | Answer user questions using retrieved project context | Free-form text |

Step 3 (Fetch URLs) and Step 6 (Generate Embedding) do not use LLM prompts -- they are pure HTTP service calls.

## Prompt Pattern

Every structured prompt follows the same pattern:

1. **Context** -- Provide the input text or data
2. **Task definition** -- Explain what the model should do
3. **Criteria** -- List specific rules or categories
4. **Output schema** -- Show the exact JSON structure expected
5. **Closing instruction** -- `"Return ONLY valid JSON matching this structure"`

## Example: Validate Project Prompt

This prompt demonstrates the pattern used across all pipeline steps:

```
Analyze this text from a Hacker News "What are you working on?" thread.

Text:
{raw_text}

Determine if this describes a VALID PROJECT or PRODUCT.

A VALID project is:
- A software application, website, tool, or service being built
- A hardware product or physical invention
- A creative work (game, book, course, art project) with tangible output
- An open source library or framework
- A startup or business venture
- A technical craft or specialized skill project

NOT valid (should be filtered):
- Personal life activities ("cleaning garage", "moving house")
- General learning/studying without building something
- Just asking questions or making comments
- Job hunting or career discussions
- Vague statements without concrete deliverables

Return a JSON object with exactly these fields:
{
  "is_valid": true/false,
  "reason": "brief explanation"
}

Return ONLY the JSON, nothing else.
```

## Individual Prompts

### 1. Extract Projects

**Purpose:** Identify and split multiple projects from a single HN comment.

**Input variable:** `comment_text`

**Behavior:**
- Single project -- returns a one-element JSON array with the full text
- Multiple projects -- splits them into separate array elements, each with enough context to stand alone
- Non-project text -- returns the original text as a single element (filtered in the next step)

**Output:** `["First project description...", "Second project description..."]`

### 2. Validate Project

**Purpose:** Filter out non-project comments before further processing.

**Input variable:** `raw_text`

**Valid projects include:** software, hardware, creative works, open source libraries, startups, technical crafts.

**Filtered out:** personal activities, general learning, questions, job hunting, vague statements.

**Output:** `{"is_valid": true, "reason": "brief explanation"}`

### 3. Generate Metadata

**Purpose:** Produce structured metadata from the raw project text and any fetched URL content.

**Input variables:** `raw_text`, `url_context`

**Generated fields:**
- `title` -- Project name, or a concise 3-7 word descriptive title if not stated
- `short_description` -- 5-10 word summary
- `description` -- 1-2 sentence explanation starting with what type of thing it is
- `hashtags` -- 3-5 lowercase single-word tags (e.g., `["ai", "python", "saas"]`)
- `url_summaries` -- Map of each URL to a 1-2 sentence summary of its content

### 4. Score Project

**Purpose:** Rate the project on two dimensions with reasoning.

**Input variables:** `title`, `description`, `raw_text`

**Scoring rubric:**

| Score | Idea Quality | Complexity |
|-------|-------------|------------|
| 1-2 | Very weak, no clear value | Very simple, built in a day |
| 3-4 | Basic, nothing novel | Simple, basic features |
| 5-6 | Decent, addresses a real need | Moderate, multiple components |
| 7-8 | Good, clear value, interesting | Complex, significant engineering |
| 9-10 | Excellent, innovative | Highly complex, cutting-edge |

**Output:** `{"idea_score": 7, "complexity_score": 5, "idea_reasoning": "...", "complexity_reasoning": "..."}`

### 5. Chatbot Response

**Purpose:** Generate a conversational response using retrieved project context.

**Input variables:** `system_prompt`, `context`, `query`

The chatbot prompt differs from the others -- it produces free-form text, not JSON. It includes a system prompt that instructs the model to:

- Base answers on the provided project context
- Mention specific projects by name
- Include details like descriptions, tags, and scores when helpful
- Acknowledge honestly when no relevant projects are found
- Maintain a helpful, conversational tone

## Workflow Steps Registry

All prompts are registered in the `WORKFLOW_STEPS` list in `src/workflows/prompts.py`. This registry makes every step and its prompt template inspectable via the API, including the template variables each prompt expects.

## Source Files

- **All prompt templates**: `src/workflows/prompts.py`
- **LLM configuration**: `src/llm_config.py`

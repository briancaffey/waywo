---
title: Debugging
description: Built-in debugging tools and observability dashboards available in the waywo development stack.
navigation.icon: i-lucide-bug
---

# Debugging

Waywo ships with several built-in tools for inspecting every layer of the system at runtime. All are accessible when running via Docker Compose.

## Debugging Dashboards

| Tool | URL | Purpose |
|------|-----|---------|
| FastAPI Swagger UI | [localhost:8008/docs](http://localhost:8008/docs) | Interactive API testing for all 45+ endpoints |
| Flower | [localhost:5555](http://localhost:5555) | Celery task monitoring and inspection |
| Phoenix | [localhost:6006](http://localhost:6006) | LLM tracing and observability |
| Redis Insights | [localhost:7001](http://localhost:7001) | Redis key inspection and memory stats |
| Jupyter Lab | [localhost:8888](http://localhost:8888) | Interactive Python exploration |
| Debug Page | [localhost:3000/debug](http://localhost:3000/debug) | Frontend debug tools |
| Prompts Page | [localhost:3000/prompts](http://localhost:3000/prompts) | Inspect all LLM prompt templates |

## FastAPI Swagger UI

Available at `/docs` on the backend. Lets you call any API endpoint directly from the browser with auto-generated request forms.

Useful for:
- Testing data ingestion (`POST /api/process-waywo-posts`)
- Triggering single comment processing (`POST /api/waywo-comments/{id}/process`)
- Running semantic search queries (`POST /api/semantic-search`)
- Checking service health (`GET /api/admin/services-health`)
- Resetting databases during development (`DELETE /api/admin/reset-all`)

## Flower -- Celery Task Monitor

Flower provides a real-time web UI for the Celery task queue. It runs on port 5555.

What you can see:
- **Active tasks** -- Currently running tasks and their arguments
- **Task history** -- Completed, failed, and retried tasks with full result data
- **Worker status** -- Worker concurrency, pool size, active/idle state
- **Task rate** -- Throughput graphs over time
- **Queue depth** -- Number of pending tasks in each queue

This is the first place to look when a task seems stuck or produces unexpected results.

## Phoenix -- LLM Observability

Phoenix (by Arize AI) traces every LLM call, embedding request, and workflow step. It runs on port 6006.

The backend sends OpenTelemetry traces via `openinference-instrumentation-llama-index`, so Phoenix captures:
- **Every LLM prompt and response** -- Full input/output text for each Nemotron call
- **Embedding calls** -- Input text and vector dimensions
- **Latencies** -- Time spent in each workflow step
- **Token counts** -- Input/output tokens per LLM call
- **Workflow traces** -- End-to-end trace spanning all steps of `WaywoProjectWorkflow` and `WaywoChatbotWorkflow`

::callout{type="tip"}
Phoenix is especially useful for debugging prompt quality. You can see the exact prompt sent to the LLM and the raw response, making it easy to iterate on templates in `src/workflows/prompts.py`.
::

## Redis Insights

Redis Insights provides a GUI for browsing Redis keys, inspecting values, and monitoring memory usage. It runs on port 7001.

Useful for:
- Checking Celery broker queue state
- Inspecting cached data
- Monitoring memory consumption

## Jupyter Lab

Jupyter Lab runs on port 8888 with no authentication token. It mounts the `notebooks/`, `src/`, and `data/` directories, so you can import any module and query the database interactively.

```python
from src.db_client import get_all_projects, semantic_search
from src.database import init_db

init_db()
projects = get_all_projects(limit=10)
```

## Frontend Debug Page

The `/debug` page in the Nuxt frontend provides quick access to:
- Celery debug task trigger
- Service health checks
- Backend connectivity status

## Workflow Prompts Page

The `/prompts` page displays every workflow step registered in `WORKFLOW_STEPS` (from `src/workflows/prompts.py`), including:
- Step name and description
- Input/output event types
- Full prompt template text
- Template variables

This is backed by the `GET /api/workflow-prompts` endpoint.

## Logging

The backend log level is controlled by the `LOG_LEVEL` environment variable (default: `DEBUG`). Celery workers log at `info` level by default.

In Docker Compose, view logs with:

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f backend
docker compose logs -f celery-worker
```

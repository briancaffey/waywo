---
title: Troubleshooting
description: Common issues, their symptoms, and solutions for debugging a Waywo deployment.
navigation.icon: i-lucide-wrench
---

# Troubleshooting

Common problems organized by symptom. Each entry follows the pattern: **Problem**, **Symptoms**, **Solution**.

## Embedding Service Unreachable

**Problem:** The embedding service at `EMBEDDING_URL` is down or unreachable from the Docker network.

**Symptoms:**
- Projects are created without embeddings (`description_embedding` is NULL)
- Semantic search returns zero results
- `/api/embedding/health` returns 503 or times out

**Solution:**
1. Verify the embedding service is running on the target host
2. Check `EMBEDDING_URL` in `docker-compose.yml` -- ensure the IP and port are correct
3. From inside a container, test connectivity:
   ```bash
   docker compose exec backend curl -s http://192.168.5.96:8000/health
   ```
4. If the service is on a different subnet, verify network routing from the Docker host
5. After fixing, re-process comments to generate missing embeddings:
   ```bash
   curl -X POST http://localhost:8008/api/process-waywo-comments
   ```

## LLM Timeouts

**Problem:** The LLM inference server is slow or unreachable.

**Symptoms:**
- Workflow steps hang for extended periods then fail
- Celery tasks show as `STARTED` in Flower but never complete
- Phoenix traces show long latencies on LLM call spans

**Solution:**
1. Check that `LLM_BASE_URL` points to a running inference server
2. Verify the model is loaded:
   ```bash
   curl -s http://192.168.6.19:8002/v1/models | jq .
   ```
3. Check GPU memory on the inference server -- the model may have been evicted
4. Review timeout settings in the workflow code if calls are succeeding but slowly
5. Check `/api/admin/services-health` for the full status of all AI services

## Celery Tasks Stuck

**Problem:** Tasks are queued but never picked up by workers.

**Symptoms:**
- Tasks show as `PENDING` in Flower indefinitely
- The Flower Workers tab shows no active workers, or workers are offline
- API calls that queue tasks return successfully but nothing happens

**Solution:**
1. Check if the celery-worker container is running and healthy:
   ```bash
   docker compose ps celery-worker
   ```
2. Check worker logs for errors:
   ```bash
   docker compose logs --tail=50 celery-worker
   ```
3. Verify Redis connectivity -- the worker needs to reach `redis://redis:6379/0`
4. Restart the worker:
   ```bash
   docker compose restart celery-worker
   ```
5. Confirm the worker is listening on the correct queue (`waywo`). In Flower, check the Queues tab.

::note
The `watchmedo auto-restart` wrapper monitors for Python file changes and restarts the worker automatically. If a syntax error is introduced, the worker may enter a restart loop. Check logs for import errors.
::

## Vector Index Not Returning Results

**Problem:** Semantic search returns empty results even though projects exist.

**Symptoms:**
- `POST /api/semantic-search` returns `{"results": [], "total": 0}`
- `/api/semantic-search/stats` shows `embedding_coverage: 0` or very low coverage

**Solution:**
1. Check embedding coverage:
   ```bash
   curl -s http://localhost:8008/api/semantic-search/stats | jq .
   ```
2. If `projects_with_embeddings` is 0, the embedding service was likely unavailable during processing. Re-process comments:
   ```bash
   curl -X POST http://localhost:8008/api/process-waywo-comments
   ```
3. Rebuild the vector index:
   ```bash
   curl -X POST http://localhost:8008/api/admin/rebuild-vector-index
   ```
4. Verify the embedding service is healthy before re-processing:
   ```bash
   curl -s http://localhost:8008/api/embedding/health | jq .
   ```

## Docker Networking Issues

**Problem:** Services inside Docker cannot reach external IPs (GPU servers, Firecrawl on the host).

**Symptoms:**
- Health checks for LLM, embedding, or rerank services fail with connection errors
- Firecrawl URL scraping fails
- Services work when tested from the host but not from inside containers

**Solution:**
1. Verify `extra_hosts` is configured on the service:
   ```yaml
   extra_hosts:
     - "host.docker.internal:host-gateway"
   ```
2. Test DNS resolution inside the container:
   ```bash
   docker compose exec backend getent hosts host.docker.internal
   ```
3. For services on external IPs (not the Docker host), verify the Docker host can route to them:
   ```bash
   docker compose exec backend curl -s --connect-timeout 5 http://192.168.5.96:8000/health
   ```
4. As a last resort, try running the service with host network mode:
   ```yaml
   network_mode: host
   ```

::warning
Using `network_mode: host` bypasses Docker networking entirely. The service will share the host's network stack and can no longer use Docker DNS names like `redis` to reach other containers. Only use this for debugging.
::

## Database Locked

**Problem:** SQLite reports "database is locked" errors.

**Symptoms:**
- Error messages containing `sqlite3.OperationalError: database is locked`
- Intermittent 500 errors from the backend API
- Celery tasks failing with database errors

**Solution:**
1. SQLite supports only one writer at a time. If multiple Celery workers are running with concurrency > 1, reduce concurrency to 1:
   ```
   --concurrency=1
   ```
2. Check for long-running transactions -- a stuck migration or a debug session holding a write lock will block all other writers
3. Verify no external process (like a database browser) has an open write transaction on `./data/waywo.db`
4. Restart all services to clear any stale connections:
   ```bash
   docker compose restart
   ```
5. If the problem persists under normal load, consider migrating to PostgreSQL (see [Scaling Considerations](/operations/scaling))

## Celery Beat Not Scheduling

**Problem:** Periodic tasks defined in the beat schedule are not firing.

**Symptoms:**
- No new post collection tasks appear in Flower on schedule
- The celery-beat container is running but its logs show no schedule activity

**Solution:**
1. Check celery-beat logs:
   ```bash
   docker compose logs --tail=50 celery-beat
   ```
2. The beat schedule database is stored in the `celery-beat-data` volume. A corrupted schedule file can prevent scheduling. Delete the volume and restart:
   ```bash
   docker compose down
   docker volume rm waywo_celery-beat-data
   docker compose up -d
   ```
3. Verify the beat process is running:
   ```bash
   docker compose ps celery-beat
   ```

## NAT Service Errors

**Problem:** The NAT (LLM workflow) service is not responding.

**Symptoms:**
- `/api/nat/health` returns 503
- Chatbot or workflow features that depend on NAT fail

**Solution:**
1. Check if the nat container is running:
   ```bash
   docker compose ps nat
   ```
2. Check nat logs for startup errors:
   ```bash
   docker compose logs --tail=50 nat
   ```
3. Verify the nat service can reach the LLM server (it uses `LLM_BASE_URL` from its environment)
4. Test the health endpoint directly:
   ```bash
   curl -s http://localhost:8080/health
   ```

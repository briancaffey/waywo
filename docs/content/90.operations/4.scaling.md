---
title: Scaling Considerations
description: Guidance on scaling Celery workers, the embedding service, SQLite limitations, and external API constraints.
navigation.icon: i-lucide-trending-up
---

# Scaling Considerations

Waywo is designed for single-machine deployment. This page covers the knobs available for scaling within that constraint, and what to consider if you outgrow it.

## Celery Workers

The celery-worker service is configured with `--concurrency=1`, meaning tasks execute serially within a single worker process.

```
celery -A src.celery_app worker --loglevel=info --queues=waywo --concurrency=1
```

This is intentional: each task makes multiple LLM calls (extract, validate, metadata, score) and embedding requests. Running tasks in parallel can overwhelm GPU servers with concurrent inference requests.

### Increasing Throughput

**Option 1: Increase concurrency** -- Raise `--concurrency` to 2 or 3 if your LLM and embedding servers can handle the additional load. Edit the celery-worker command in `docker-compose.yml`.

**Option 2: Add more worker containers** -- Duplicate the celery-worker service definition with a different container name. Each worker will pull tasks from the same `waywo` queue in Redis.

```yaml
celery-worker-2:
  build: .
  container_name: waywo-celery-worker-2
  environment:
    <<: *common-env
  volumes: *common-volumes
  command: >
    /app/.venv/bin/celery -A src.celery_app worker
    --loglevel=info --queues=waywo --concurrency=1
  depends_on:
    redis:
      condition: service_healthy
    migrate:
      condition: service_completed_successfully
  networks:
    - waywo-network
  extra_hosts:
    - "host.docker.internal:host-gateway"
```

::warning
Adding workers increases concurrent writes to SQLite. With WAL mode, concurrent reads are fine, but SQLite only supports a single writer at a time. Multiple workers may see occasional "database is locked" errors under heavy load.
::

## Embedding Service

The embedding service is stateless -- it takes text in and returns vectors. You can run multiple instances behind a load balancer if embedding becomes a bottleneck. Each instance needs GPU access for reasonable performance.

## Rerank Service

Like the embedding service, the rerank service is stateless and can be scaled horizontally. It processes query-document pairs and returns relevance scores.

## SQLite Limitations

SQLite is a single-writer database. Key constraints:

| Aspect | Behavior |
|--------|----------|
| Concurrent reads | Supported with WAL mode (enabled by default) |
| Concurrent writes | **Single writer at a time** -- other writers block or get "database is locked" |
| Maximum database size | ~281 TB (practical limit is disk space) |
| Network access | File-based only -- no client-server protocol |

For the typical Waywo workload (periodic batch processing, low concurrent writes), SQLite works well. The main risk is multiple Celery workers or the backend all trying to write simultaneously.

## External API Constraints

### Hacker News API

The HN Firebase API has no documented rate limit, but it is a public service. Waywo fetches posts and comments sequentially within each Celery task, which keeps request volume low. Be respectful -- avoid running many collection tasks in parallel.

### Firecrawl

Firecrawl is used to scrape URLs found in comments. If running a self-hosted instance, throughput depends on your deployment. If using the hosted service, check their rate limit documentation.

### LLM / Embedding / Rerank Servers

These are self-hosted GPU services. Throughput depends on your hardware. Monitor GPU utilization and request latency in Phoenix traces to identify bottlenecks.

## When to Consider PostgreSQL

If you need any of the following, consider migrating to PostgreSQL with pgvector:

- **Multiple concurrent writers** -- PostgreSQL handles concurrent writes natively
- **Network database access** -- Multiple application servers connecting to one database
- **Advanced querying** -- Full-text search, complex joins at scale, JSONB indexing
- **Managed backups** -- Point-in-time recovery, streaming replication
- **Larger vector workloads** -- pgvector supports HNSW and IVFFlat indexes for faster approximate search

The migration path would involve:
1. Replacing SQLAlchemy's SQLite engine with a PostgreSQL engine
2. Swapping sqlite-vector calls for pgvector operations
3. Updating the `vector_init` / `vector_full_scan` calls to use pgvector's `<=>` cosine distance operator
4. Running schema migrations against the new database

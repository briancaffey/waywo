---
title: Celery Task
description: The generate_ideas task that orchestrates pipeline execution, embedding, and storage.
navigation.icon: i-lucide-cog
---

# Generate Ideas Task

The `generate_ideas` Celery task in `src/worker/tasks.py` orchestrates the full generation flow. It runs on the `waywo` queue alongside the HN processing tasks.

## Task Signature

```python
@celery_app.task(name="generate_ideas", bind=True)
def generate_ideas(
    self,
    num_ideas: int = 5,
    seed_tags: list[str] | None = None,
    creativity: float = 0.85,
) -> dict
```

| Parameter | Type | Default | Description |
|---|---|---|---|
| `num_ideas` | `int` | `5` | Number of project ideas to generate (1--50) |
| `seed_tags` | `list[str] \| None` | `None` | Tags to guide generation; `None` uses the full vocabulary |
| `creativity` | `float` | `0.85` | LLM temperature for creative generation (0.1--1.5) |

## Execution Stages

The task reports its progress through Celery state updates, which the frontend polls to show a progress bar.

### Stage 1: Building Pipeline

```python
self.update_state(
    state="STARTED",
    meta={"stage": "building_pipeline", "progress": 0, "total": num_ideas},
)
```

- Loads all existing projects from the database
- Computes tag co-occurrence statistics
- Fetches the full tag vocabulary
- Builds the NDD provider, model configs, and pipeline

### Stage 2: Generating

```python
self.update_state(
    state="STARTED",
    meta={"stage": "generating", "progress": 0, "total": num_ideas},
)
```

- Calls `DataDesigner.create(config, num_records=num_ideas)`
- NDD runs each column processor sequentially for all rows
- Loads the result DataFrame via `result.load_dataset()`

### Stage 3: Saving

```python
self.update_state(
    state="STARTED",
    meta={"stage": "saving", "progress": i, "total": len(df)},
)
```

For each generated row:

1. **Parse hashtags** -- The expression column produces a Python list repr string (single quotes); parsed with `ast.literal_eval` which handles this correctly
2. **Parse scores** -- Extract `idea_score` and `complexity_score` from the judge output
3. **Create WaywoProject** -- Build a Pydantic model with `source="nemo_data_designer"` and `source_comment_id=None`
4. **Generate embedding** -- Call the embedding service to create a 4096-dim vector
5. **Save to database** -- Store project + embedding in SQLite

## Return Value

On success:

```json
{
  "status": "success",
  "num_requested": 5,
  "num_generated": 5,
  "num_saved": 5,
  "project_ids": [101, 102, 103, 104, 105],
  "errors": [],
  "seed_tags": ["nutrition", "ios"]
}
```

On partial failure (some rows failed):

```json
{
  "status": "partial",
  "num_requested": 5,
  "num_generated": 5,
  "num_saved": 3,
  "project_ids": [101, 102, 103],
  "errors": [
    {"row": 3, "error": "Embedding service unavailable"},
    {"row": 4, "error": "Invalid metadata format"}
  ],
  "seed_tags": ["nutrition", "ios"]
}
```

## Error Handling

- Individual row failures are caught and recorded in `errors` without aborting the batch
- If the entire NDD pipeline fails, the task raises an exception and transitions to `FAILURE` state
- The frontend displays error details from both the `errors` array and the task failure message

---
title: Content Safety
description: How Waywo uses a dedicated content safety model to classify and block harmful or off-topic requests in both text and voice chat.
navigation.icon: i-lucide-shield-check
---

# Content Safety

Waywo uses [Nemotron-Content-Safety-Reasoning-4B](https://huggingface.co/nvidia/Nemotron-Content-Safety-Reasoning-4B) to classify user prompts and LLM responses before they reach the user. This keeps conversations on topic and blocks harmful content across both text chat and voice chat.

## How It Works

Every chat interaction passes through two safety gates:

```
User message
  |
  v
[Gate 1] Classify user prompt ── harmful? → return blocked message
  |                                          (skip agent entirely)
  | unharmful
  v
Agent execution (RAG + LLM)
  |
  v
[Gate 2] Classify LLM response ── harmful? → replace with blocked message
  |
  | unharmful
  v
Return response to user
```

Both gates make a single async HTTP call to the content safety model. If the model classifies the input or output as harmful, a canned refusal message is returned instead. The agent and LLM are never invoked for blocked prompts, saving compute.

## The Model

Nemotron-Content-Safety-Reasoning-4B is a 4B parameter model fine-tuned from Google's Gemma-3-4B-it. It classifies content as `harmful` or `unharmful` based on a custom safety policy.

Key properties:

- **Custom policies** -- the model adapts to user-defined safety rules rather than using a fixed taxonomy
- **Two modes** -- `/no_think` for low-latency classification (used in production), `/think` for classification with a reasoning trace (useful for debugging)
- **Dual classification** -- evaluates both the user prompt and the assistant response independently

The model runs via vLLM on a dedicated GPU, exposing an OpenAI-compatible API.

## Safety Policy

The policy is defined in `src/clients/content_safety.py` and tailored to the Waywo use case:

**Blocked:**
- Violence, threats, harassment, hate speech
- Sexual or explicit content
- Illegal activity or criminal planning
- Personal information disclosure
- Financial advice, gambling strategies, betting tips
- Content completely unrelated to software projects or technology

**Allowed:**
- Questions about software projects, programming, or technology
- Project recommendations and comparisons
- Technical discussions (including security tools)
- Casual greetings that lead into on-topic conversation

## Integration Points

The safety gates are integrated into both chat interfaces:

| Route | File | Input Gate | Output Gate |
|-------|------|-----------|-------------|
| Text chat (REST) | `src/routes/chat.py` | Before agent execution | After LLM response |
| Text chat (SSE streaming) | `src/routes/chat.py` | Before agent execution | After full response collected |
| Voice chat (WebSocket) | `src/routes/voice.py` | After STT transcription | Before TTS generation |

For voice chat, when a prompt is blocked, the blocked message is synthesized via TTS and sent back as audio so the user hears the refusal naturally.

## Graceful Degradation

The service is designed to **fail open**. If the content safety model is unavailable or times out:

- Requests are allowed through without classification
- A warning is logged
- The chatbot continues to function normally

This is appropriate because Waywo is a project discovery tool, not a high-risk application.

## Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `CONTENT_SAFETY_URL` | `http://192.168.5.253:8085` | vLLM service URL |
| `CONTENT_SAFETY_ENABLED` | `true` | Set to `false` to disable safety checks |
| `CONTENT_SAFETY_TIMEOUT` | `10` | Request timeout in seconds |

## Running the Service

The content safety model runs as a standalone vLLM container. See `services/content-safety/README.md` for the Docker command and configuration details.

::warning
You must use `--dtype bfloat16` when serving this model. The Gemma-3 architecture has numerical instability with float16 that causes the model to output only padding tokens.
::

## File Map

| File | Role |
|------|------|
| `src/clients/content_safety.py` | Async client -- `classify_prompt()`, `classify_exchange()`, health check |
| `src/routes/chat.py` | Input and output safety gates for text chat |
| `src/routes/voice.py` | Input and output safety gates for voice chat |
| `src/routes/admin.py` | Content safety health check in services-health endpoint |
| `src/settings.py` | `CONTENT_SAFETY_URL`, `CONTENT_SAFETY_ENABLED`, `CONTENT_SAFETY_TIMEOUT` |
| `services/content-safety/README.md` | Docker setup and vLLM configuration |

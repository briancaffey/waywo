---
title: Semantic Search
description: End-to-end flow of a semantic search query, from text input through vector similarity to ranked project results.
navigation.icon: i-lucide-scan-search
---

# Semantic Search

Semantic search lets you find projects by meaning rather than exact keywords. A query like "real-time collaboration" will surface projects about multiplayer editors, shared whiteboards, and live coding tools -- even if they never use the word "collaboration."

## Search Flow

```
User query
  |
  v
POST /api/semantic-search
  |
  v
Embedding service (llama-embed-nemotron-8b, 4096 dims)
  |
  v
sqlite-vector cosine similarity scan
  |
  v
(optional) Rerank via llama-nemotron-rerank
  |
  v
Top-k results with scores
```

### Step 1 -- Embed the Query

The query string is sent to the NVIDIA embedding service, which returns a 4096-dimensional float vector:

```python
query_embedding = await get_single_embedding(
    text=request.query,
    embedding_url=embedding_url,
)
```

The embedding client includes automatic retries with exponential backoff (up to 3 attempts) and a 60-second timeout.

### Step 2 -- Vector Similarity Search

The query embedding is packed into a binary blob and passed to sqlite-vector's `vector_full_scan`:

```sql
SELECT p.id, v.distance
FROM waywo_projects AS p
JOIN vector_full_scan(
    'waywo_projects', 'description_embedding', :query, :limit
) AS v ON p.id = v.rowid
WHERE p.is_valid_project = :is_valid
ORDER BY v.distance ASC
```

- Only valid projects are returned (`is_valid_project = true`)
- Results are ordered by cosine distance (lower = more similar)
- Distance is converted to a similarity score: `similarity = 1.0 - (distance / 2.0)`

### Step 3 -- Rerank (Optional)

When `use_rerank` is `true` (the default), the endpoint fetches `limit * 3` candidates from vector search, then passes them to the rerank service:

```python
documents = [
    f"{project.title}: {project.description}"
    for project, _ in results
]

rerank_result = await rerank_documents(
    query=request.query,
    documents=documents,
    rerank_url=rerank_url,
)
```

The reranker (llama-nemotron-rerank-1b) uses a cross-encoder architecture to score each candidate against the query. Results are reordered by rerank score, and the top `limit` are returned. If the reranker is unavailable, the endpoint falls back to similarity-based ordering.

### Step 4 -- Response

Each result includes the full project data plus scores:

```json
{
  "results": [
    {
      "project": { "id": 42, "title": "CollabPad", ... },
      "similarity": 0.8723,
      "rerank_score": 0.9451
    }
  ],
  "query": "real-time collaboration",
  "total": 10,
  "reranked": true
}
```

## The WaywoVectorStore Adapter

The `WaywoVectorStore` class in `src/workflows/waywo_chatbot_workflow.py` bridges LlamaIndex's `BasePydanticVectorStore` interface with the sqlite-vector search implementation. It is used internally by the RAG chatbot workflow:

- Read-only (no `add` or `delete` -- embeddings are managed during project processing)
- Delegates to `semantic_search()` from `src/db_client.py`
- Converts results into LlamaIndex `TextNode` objects with metadata (title, hashtags, scores)

## Stats Endpoint

Check embedding coverage at any time:

**`GET /api/semantic-search/stats`**

```json
{
  "total_projects": 1250,
  "projects_with_embeddings": 1180,
  "embedding_coverage": 94.4
}
```

Projects without embeddings are invisible to search. See the [Tuning](/search-and-rag/tuning) section for guidance on improving coverage.
